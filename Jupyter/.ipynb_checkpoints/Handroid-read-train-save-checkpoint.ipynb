{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Jupyter cells as wide as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directory \n",
    "Set the directory to read motion files from.<br>\n",
    "This directory should contain a set of sub-directories where the name matches the motion label.<br>\n",
    "Each sub-directory contains a set of comma-separated (.csv) files each containing a single captured motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName = 'closeMotions' #to be used for exporting graphs and the trained ML model\n",
    "rootDir = 'V:/Dropbox/ShareIrene/ScienceFair/Experiments/DataFiles'\n",
    "closeMotions = '20180303_2333'\n",
    "distinctMotions = '20180217_2314'\n",
    "\n",
    "dataName = distinctMotions #dataName is used later to save a png of the plots\n",
    "dataRootDir = os.path.join(rootDir, dataName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process csv file functions\n",
    "\n",
    "The main function 'read_csv_files' loops through the sub-directories of the root and reads the .csv files.<br>\n",
    "It calls the functions 'add_csv_df' and 'prepare_csv_df' to convert the motion data into a single DataFrame that can be processed by the SKLearn toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_csv_files function\n",
    "This procedure starts from a root directory and loops over each sub-directory.<br>\n",
    "Each sub-directory represents one class of motions. The directory name is the label for this motion.<br>\n",
    "Each sub-directory contains a set of .csv files. Each .csv file is one captured motion.<br>\n",
    "It returns a DataFrame where each motion is one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# motions_dict = {}\n",
    "def read_csv_files(rootDir):\n",
    "    df_list = []\n",
    "    for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "        if dirName == rootDir:\n",
    "            motionName = ''\n",
    "        else:\n",
    "            head, motionName = os.path.split(dirName) #split removes the directory separator, so we don't need to do this by replacing '\\' or '/'\n",
    "        if len(motionName) > 0:\n",
    "#             print('Motion: %s' % motionName)\n",
    "            for fname in fileList:\n",
    "                filename, file_extension = os.path.splitext(fname)\n",
    "                #Only consider csv files\n",
    "                if file_extension.lower() == '.csv':   \n",
    "                    csv_file = os.path.join(dirName, fname)\n",
    "                    fileSize = os.path.getsize(csv_file)\n",
    "                    dataName = fname.replace('.CSV', '')\n",
    "#                     print('\\t%s, size = %i, data = %s' % (fname, fileSize, dataName))\n",
    "                    if (fileSize > 0):\n",
    "                        df = pd.read_csv(csv_file)\n",
    "                        if len(df.index) >= 48:\n",
    "                            df = df.head(48)\n",
    "                            if not df.isnull().values.any():\n",
    "                                add_csv_df(df_list, df, dataName, motionName)\n",
    "                            else:\n",
    "                                print('Found null values')\n",
    "                        else :\n",
    "                            print('Less than 49 samples: ' + fname)\n",
    "    all_df = pd.concat(df_list)\n",
    "    all_df.columns.names = ['sample','qt']\n",
    "    if all_df.isnull().values.any():\n",
    "        print (\"NULL\")\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add_csv_df function\n",
    "Adds a DataFrame representing a single .csv file to the list 'df_list'.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_csv_df(df_list, csv_df, dataName, motion):\n",
    "    df = prepare_csv_df(csv_df, dataName, motion)\n",
    "    if df.isnull().values.any():\n",
    "        print(\"Null values\")\n",
    "    df_list.append(prepare_csv_df(csv_df, dataName, motion))\n",
    "#     return none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare_csv_df function\n",
    "Takes the raw csv data, extracts the quaternions, stacks the sampled data in one column and then transposes it to a single row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_csv_df(csv_df, dataName, motion):\n",
    "    #1. Extract quaternion columns from csv_df\n",
    "    df = csv_df[['quat_w','quat_x','quat_y','quat_z']]\n",
    "    #2. Transpose (stack)\n",
    "    df = pd.DataFrame(df.stack())\n",
    "    #3. Name data column (multi-index)\n",
    "    columns = [(motion,dataName)]\n",
    "    df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "    #4. Transpose\n",
    "    df = df.T\n",
    "    df.index.names = ['motion', 'dataName']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the motions from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c67bdcb0e4c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataRootDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-96492cc65a54>\u001b[0m in \u001b[0;36mread_csv_files\u001b[1;34m(rootDir)\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Less than 49 samples: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mall_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sample'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'qt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                        copy=copy)\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py35\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "all_df = read_csv_files(dataRootDir)\n",
    "all_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare machine learning data\n",
    "Convert the motions into the X (input) matrix and Y (output) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_df\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = all_df.reset_index()['motion']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any 'null' values. Nulls cause trouble in the learning algorithm and need to be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn\n",
    "1. Label encoding\n",
    "2. Split data set into a train and test set\n",
    "3. Train GaussianNB model and test\n",
    "4. Train RandomForrest model and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "We need to map the textual values of the predicted labels to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(Y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the data to training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.5, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnbModel = gnb.fit(X_train, y_train)\n",
    "y_pred = gnbModel.predict(X_train)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_train.shape[0],(y_train != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "### call pipeline.predict() on your X_test data to make a set of test predictions\n",
    "y_prediction = gnbModel.predict( X_test )\n",
    "### test your predictions using sklearn.classification_report()\n",
    "report = classification_report( y_test, y_prediction )\n",
    "### and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed report on test data\n",
    "For each item in the test set, get the detailed (probability-based) prediction and compare with actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_proba = gnbModel.predict_proba(X_test)\n",
    "df = pd.DataFrame(y_prediction_proba, columns = le.classes_)\n",
    "df['correct']=(y_prediction == y_test)\n",
    "df['predicted']=le.inverse_transform(y_prediction)\n",
    "df['actual']=le.inverse_transform(y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot probability data in histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['correct', 'predicted', 'actual'], axis=1)\n",
    "df2.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier()\n",
    "rdfModel = rdf.fit(X_train, y_train)\n",
    "y_pred = rdfModel.predict(X_train)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_train.shape[0],(y_train != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "### call pipeline.predict() on your X_test data to make a set of test predictions\n",
    "y_prediction = rdfModel.predict( X_test )\n",
    "### test your predictions using sklearn.classification_report()\n",
    "report = classification_report( y_test, y_prediction )\n",
    "### and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_proba = rdfModel.predict_proba(X_test)\n",
    "df = pd.DataFrame(y_prediction_proba, columns = le.classes_)\n",
    "df['correct']=(y_prediction == y_test)\n",
    "df['predicted']=le.inverse_transform(y_prediction)\n",
    "df['actual']=le.inverse_transform(y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.columns[1]].hist(bins=50)\n",
    "df2 = df.drop(['correct', 'predicted', 'actual'], axis=1)\n",
    "df2.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(rdfModel, modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plotting\n",
    "Plot all motion data by quaternion.\n",
    "Allows for a visual comparision of how close the motions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMultiMotions(X, qtName, motionName):\n",
    "    '''qt is the name of the quaternion (e.g. 'quat_w'). motionName is the name of the motion (e.g. 'Curl_90degree'). \n",
    "    Should match the names of the indices of df X.\n",
    "    Returns a df with multiple time-series of the quaternion of the motion type'''\n",
    "    \n",
    "    df = X.xs(qtName, level='qt', axis=1)\\\n",
    "        .xs(motionName, level='motion', axis=0)\\\n",
    "        .reset_index()\\\n",
    "        .drop(['dataName'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotMotion2D(X, motionNames):\n",
    "    numMotions = len(motionNames)\n",
    "    fig, axes = plt.subplots(nrows=numMotions, ncols=4, figsize=(20, numMotions*4))\n",
    "#     fig.suptitle(motionName, fontsize=20)\n",
    "    for motionIdx in range(0,numMotions):\n",
    "        motionName = motionNames[motionIdx]\n",
    "        for qtIdx in range(0,4):\n",
    "            axes[motionIdx][qtIdx].set_autoscaley_on(False)\n",
    "            axes[motionIdx][qtIdx].set_ylim([-1,1])\n",
    "        \n",
    "        axes[motionIdx][0].set_ylabel(motionName)\n",
    "        axes[motionIdx][0].set_title('w')\n",
    "        axes[motionIdx][1].set_title('x')\n",
    "        axes[motionIdx][2].set_title('y')\n",
    "        axes[motionIdx][3].set_title('z')\n",
    "        axes[motionIdx][0].plot(getMultiMotions(X, 'quat_w', motionName).T)\n",
    "        axes[motionIdx][1].plot(getMultiMotions(X, 'quat_x', motionName).T)\n",
    "        axes[motionIdx][2].plot(getMultiMotions(X, 'quat_y', motionName).T)\n",
    "        axes[motionIdx][3].plot(getMultiMotions(X, 'quat_z', motionName).T)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motionNames = X.index.levels[0].tolist()\n",
    "motionNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotMotion2D(X, motionNames)\n",
    "plt.savefig('Handoid-Motions-'+dataName+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.5.4)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
